{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Solana Portfolio Tracker\n",
    "\n",
    "This notebook will track Solana wallet portfolios and display trading data in a custom format.\n",
    "\n",
    "**Target Wallet:** `9QEHSyTqyRNDSvbYtFjqR2e5UXNfvjpAcEdTqAjSwVmH`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import necessary libraries for web scraping\nimport requests\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport json\nfrom datetime import datetime\nfrom bs4 import BeautifulSoup\nimport time\n\n# Set display options for better readability\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\n\nprint(\"Libraries loaded! Ready to scrape Jupiter portfolio data.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the wallet address to track\n",
    "WALLET_ADDRESS = \"9QEHSyTqyRNDSvbYtFjqR2e5UXNfvjpAcEdTqAjSwVmH\"\n",
    "\n",
    "print(f\"Tracking wallet: {WALLET_ADDRESS}\")\n",
    "print(f\"Jupiter Portfolio URL: https://jup.ag/portfolio/{WALLET_ADDRESS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Research Available APIs\n",
    "\n",
    "We need to find APIs that can give us:\n",
    "- Wallet token balances\n",
    "- Transaction history\n",
    "- Token prices\n",
    "- Trading data\n",
    "\n",
    "Potential APIs:\n",
    "- Jupiter API\n",
    "- Solana RPC\n",
    "- Solscan API\n",
    "- CoinGecko for prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Let's try to scrape the Jupiter portfolio page directly\ndef scrape_jupiter_portfolio(wallet_address):\n    \"\"\"\n    Scrape portfolio data from Jupiter website\n    \"\"\"\n    url = f\"https://jup.ag/portfolio/{wallet_address}\"\n    \n    # Set headers to mimic a real browser\n    headers = {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n    }\n    \n    try:\n        print(f\"Fetching data from: {url}\")\n        response = requests.get(url, headers=headers)\n        response.raise_for_status()\n        \n        # Parse the HTML\n        soup = BeautifulSoup(response.content, 'html.parser')\n        \n        # Jupiter likely loads data with JavaScript, so we might need to look for JSON data\n        # Let's check what we can find in the page source\n        print(f\"Page title: {soup.title.string if soup.title else 'No title'}\")\n        print(f\"Page content length: {len(response.text)} characters\")\n        \n        # Look for script tags that might contain portfolio data\n        scripts = soup.find_all('script')\n        print(f\"Found {len(scripts)} script tags\")\n        \n        return {\n            \"url\": url,\n            \"status\": \"fetched\",\n            \"content_length\": len(response.text),\n            \"scripts_found\": len(scripts)\n        }\n        \n    except requests.exceptions.RequestException as e:\n        print(f\"Error fetching data: {e}\")\n        return {\"error\": str(e)}\n\n# Test the scraping function\nresult = scrape_jupiter_portfolio(WALLET_ADDRESS)\nprint(f\"Scraping result: {result}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Collection Functions\n",
    "\n",
    "We'll create functions to:\n",
    "1. Fetch token balances\n",
    "2. Get transaction history\n",
    "3. Calculate portfolio value\n",
    "4. Track trading performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Alternative approach: Check if Jupiter has a simple API endpoint\ndef check_jupiter_api():\n    \"\"\"\n    Check if Jupiter has any accessible API endpoints\n    \"\"\"\n    # Try some common API patterns\n    api_urls = [\n        f\"https://api.jup.ag/portfolio/{WALLET_ADDRESS}\",\n        f\"https://jup.ag/api/portfolio/{WALLET_ADDRESS}\",\n        f\"https://api.jup.ag/v1/portfolio/{WALLET_ADDRESS}\"\n    ]\n    \n    for url in api_urls:\n        try:\n            print(f\"Trying API endpoint: {url}\")\n            response = requests.get(url)\n            print(f\"Status code: {response.status_code}\")\n            \n            if response.status_code == 200:\n                print(\"✅ Found working API endpoint!\")\n                data = response.json()\n                print(f\"Data preview: {str(data)[:200]}...\")\n                return url, data\n            else:\n                print(f\"❌ Not accessible (status: {response.status_code})\")\n                \n        except Exception as e:\n            print(f\"❌ Error: {e}\")\n        \n        print(\"-\" * 50)\n    \n    return None, None\n\n# Test for API endpoints\napi_url, api_data = check_jupiter_api()\n\nif api_url:\n    print(f\"Great! We can use API: {api_url}\")\nelse:\n    print(\"No direct API found. We'll need to use web scraping with browser automation.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Next Steps - Web Scraping Approach\n\nSince Jupiter loads data dynamically, we have a few options:\n\n### Option 1: Browser Automation (Recommended)\nInstall Selenium to control a real browser:\n```bash\npip install selenium\n```\n\n### Option 2: Network Analysis\nInspect Jupiter's network requests to find the actual API calls it makes\n\n### Option 3: Alternative Data Sources\nUse other Solana portfolio trackers like:\n- Solscan API\n- DeBank API\n- Direct Solana RPC calls\n\n**Let's start with Option 1 - it's the most reliable for scraping modern web apps!**"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
